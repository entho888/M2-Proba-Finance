#%%
#Libraries
import numpy as np 
import matplotlib.pyplot as plt
import scipy


rng = np.random.default_rng()

def uniform_distribution(low=float, high=float, size=None) :
    """Return an independent sample of size "size" of uniform distribution over 
    the interval [low, high).

    Args:
        low (float): lower bound of the interval the generated numbers are in
        high (float): upper bound of the interval the generated numbers are in
        size (tupple): output shape. if the given shape is (m,n,k) then m*n*k samples are generated. 
            Default is None, in the case the function returns a single value.

    Returns:
        Array of random floats of shape "size".
    """
    if low > high : 
        print("Error from 'uniform_distribution' function of 'simulation' : lower bound of interval greater than upper bound")
        return 
    return (high - low)*rng.random(size=size) + low


def exponential_distribution(lamda=float, size=None) :
    """exponential_distribution : Return an independent sample of shape "size" of 
    exponential distribution of parameter lambda = lamda. 
    Density is lamda*np.exp(-lamda*x).
    Generated by the inverse distribution function method.

    Args:
        lamda (float, optional): non negativ float, parameter of the exponential distribution.
         Defaults to float.
        size (tupple, optional): output shape. if given shape is (m,,n,k) then m*n*k samples are generated.
         Defaults to None.

    Returns :   
        Array of random floats of shape "size".
    """
    if lamda <= 0 : 
        print("Error from 'exponential_distribution' function of 'simulation' : parameter lambda is negativ")
        return
    return (-1/lamda)*np.log(rng.random(size=size))


def bernoulli(p=float, size=None) :
    def jump_function(x) :
        if x < p : return 1
        else: return 0
    jump_function_vectorized = np.vectorize(jump_function)
    return jump_function_vectorized(rng.random(size=size))


def Pascal_triangle(row_number) :
    """Pascal_triangle : Return a list of all binomial coefficients of 'degree' equal to
    'row_number'. Let's say row_number is equal to 2 then it returns [1,2,1].
    It uses the pascal triangle relation.

    Args:
        row_number (int): positiv integer, is equal to the 'degree' in the 
        binomial relation of Newton

    Returns:
        List : list of the binomial coefficents of 'degree' equal to 'row_number'
    """

    if row_number < 0 : 
        print("Error from 'Pascal_triangle' function of 'simulation' : row_number is negativ")
        return

    present_Row = []
    past_Row = [1]
    for i in range(1, row_number+1) :
        present_Row.append(1)
        for j in range(1, i) :
            present_Row.append(past_Row[j-1] + past_Row[j])
        present_Row.append(1)
        past_Row = present_Row
        present_Row = []

    return past_Row


def binomial(n=int, p=float, size=None) :
    """binomial : Return an independent sample of shape 'size' of binomial 
    distribution of parameter 'n' and 'p'. 
    Generated by the inverse distribution function method.

    Args:
        n (int, optional): non negativ integer, maximum number the distribution may take.
         Defaults to int.
        p (float, optional): float between 0 and 1, parameter of the law.
         Defaults to float.
        size (int, optional): output shape. if given shape is (m,,n,k) then m*n*k samples are generated.
         Defaults to None.

    Returns:
        Array: array of random positiv integer lower than 'n' following the binomial(n,p) distribution.
    """

    if (n <= 0) :
        print("Error in 'binomial' function of 'simulation' : n is negativ")
        return
    if (p < 0) or (p >1) :
        print("Error in 'binomial' function of 'simulation' : p must be include in [0,1]")
        return

    binomial_coefficients = Pascal_triangle(n)
    cumulated_probability_list = [0]

    Sum = 0
    for k in range(n) :
        Sum += binomial_coefficients[k]*(p**(k))*((1-p)**(n-k))
        cumulated_probability_list.append(Sum)
    cumulated_probability_list.append(1)

    def multiple_jumps_function(x) :
        for k in range(len(cumulated_probability_list)-1) :
            if x >= cumulated_probability_list[k] and x < cumulated_probability_list[k+1] :
                return k

    multiple_jumps_function_vect = np.vectorize(multiple_jumps_function)

    return multiple_jumps_function_vect(rng.random(size=size))
    

def box_muller_method(size: int=1) :
    """Implementation of the Box-Muller method to draw independent samples of standard normal distribution 
    (centered and variance is identity). 

    Args:
        size (non negativ integer): number of samples draw
    
    Returns:
        List of length 'size' of independent realisations of standard normal distribution.
    """

    try :
        iteration_number = int(np.ceil(size/2)) #number of iteration of the method needed
        uniform_sample = rng.random((iteration_number,2))
        normal_sample = []

        for i in range(iteration_number) :
            u1, u2 = uniform_sample[i,]
            exponential = (-2*np.log(u1))**(.5)
            uniform_angle = 2*np.pi*u2

            normal_sample.extend((exponential*np.cos(uniform_angle), exponential*np.sin(uniform_angle)))

        return normal_sample[:size]

    except TypeError :
        print("Enter an int")
        raise
    except ValueError :
        print("Enter a non negativ int")
        raise


def uniform_unit_ball(dimension=int, size : int=1) :
    """uniform_unit_ball : Return a list of length 'size' of independent realisations of
    uniform distribution over the unit ball of the real space to the power of 'dimension'.
    Generated using the acceptance-reject method.
    It's the unit ball for the L2 norm.

    Args:
        dimension (int, optional): dimension of the space of the ball. Defaults to int.
        size (int, optional): non negativ integer, length of the output list.
         Defaults to None.
        
    Returns :
        List of an independent sample of uniform distribution over the unit ball of R**(dimension).
    """

    U = np.empty((size, dimension))
    
    for i in range(size)  :
        u = 2*np.ones(dimension)

        while np.linalg.norm(u) > 1 :
            u = np.array(uniform_distribution(-1,1,dimension))

        U[i,:] = u

    return U


def marsaglia_method(size: int=1) :
    """Implementation of the Marsaglia's polar method to draw independent samples of standard normal distribution 
    (centered and variance is identity). 

    Improvements to make : vectorize more, don't use a loop and generate a fixed number of uniform[0,1] chose so
    we accept at least 'size' points with high probability (cf : https://quantgirl.blog/comparing-box-muller-and-marsaglia-bray/)

    Args:
        size (non negativ integer): number of samples draw
    Returns:
        List of length 'size' of independent realisations of standard normal distribution.
    """

    try :
        iteration_number = int(np.ceil(size/2)) #number of iteration of the method needed
        normal_sample_x = np.empty(iteration_number)
        normal_sample_y = np.empty(iteration_number)

        for i in range(iteration_number) :
            r=2
            while r > 1 :
                x, y = 2*rng.random(2) - 1
                r = x**2 + y**2
            
            temp = (-2*np.log(r)/r)**(.5)

            normal_sample_x[i], normal_sample_y[i] = temp*x, temp*y

        return np.concatenate((normal_sample_x, normal_sample_y), axis=0)[:size]

    except TypeError :
        print("Enter an int")
        raise
    except ValueError :
        print("Enter a non negativ int")
        raise


def gaussian_vector(mu, sigma, cholesky = bool) :
    """gaussian_distribution : Return a gaussian vector of mean 'mu' and covariance matrix
    'sigma'. Uses Box-Muller ...

    Args:
        mu (array_like): 1d array, mean vector of the gaussian vector
        sigma (array_like): 2d array of shape (n,n), where n is the shape of mu. Sigma
            is the matrix of the covariances between the variables within our gaussian vector.
            The function assumes that sigma really is a covariance matrix.
        cholesky (Boolean): if equals to 'True' then the algorithm will use the Cholesky Decomposition.
            Otherwise, it uses scipy.linalg.sqrtm. 
    Returns:
        1 array_like with same shape as mu. 
    """

    try : 
        mu, sigma = np.array(mu), np.array(sigma)
        n = len(mu)
        
        if sigma.shape != (n,n) :
            print("Error in 'gaussian_vector' of 'simulation' : shapes of parameters aren't compatible.")
            return

        if cholesky == True :
            return (np.linalg.cholesky(sigma)).dot(box_muller_method(n)) + mu
        return ((scipy.linalg.sqrtm(sigma))[0]).dot(box_muller_method(n)) + mu

    except TypeError :
        print("Error in 'gaussian_vector' of 'simulation' : enter array like parameters")
        raise

A = np.eye(2)
print(scipy.linalg.sqrtm(A))

def standard_brownian_simulation(time_list, gaussian_list) :
    Brownian_list = [gaussian_list[0]]

    for i in range(1, len(time_list)) :
        t2 = time_list[i]
        t1 = time_list[i-1]

        Brownian_list.append(Brownian_list[i-1] + np.sqrt((t2-t1))*gaussian_list[i])

    return Brownian_list


"""
times = np.linspace(0,100,N)
Brownian = standard_brownian_simulation(times, sample)
plt.plot(times, Brownian)
plt.show()
"""

# %%
